{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1, -2. ,  0. ],\n",
       "       [ 0. , -1. ,  1. ],\n",
       "       [ 0. ,  0. ,  0. ],\n",
       "       [ 0. ,  1. ,  0. ],\n",
       "       [ 0. ,  2. ,  0. ],\n",
       "       [ 0. ,  3. ,  0. ],\n",
       "       [ 0. ,  4. ,  0. ],\n",
       "       [ 0. ,  5. ,  0. ],\n",
       "       [ 0. ,  6. ,  1. ],\n",
       "       [ 0. ,  7. ,  0. ],\n",
       "       [ 0. ,  8. ,  1. ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "import numpy as np\n",
    "D = []\n",
    "file_path = \"Homework 2 data/Druns.txt\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Split the line into dimensions and label\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 3:  # Check if the line has both dimensions and a label\n",
    "            try:\n",
    "                # Parse dimensions and label as floats and integer\n",
    "                dim1 = float(parts[0])\n",
    "                dim2 = float(parts[1])\n",
    "                label = int(parts[2])\n",
    "\n",
    "                D.append([dim1, dim2, label])\n",
    "            except ValueError:\n",
    "                print(f\"Skipping invalid line: {line}\")\n",
    "\n",
    "D = np.array(D)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.is_leaf = False\n",
    "\n",
    "class LeafNode(Node):\n",
    "    def __init__(self, class_label=None):\n",
    "        super().__init__()\n",
    "        self.is_leaf = True\n",
    "        self.class_label = class_label\n",
    "\n",
    "class InternalNode(Node):\n",
    "    def __init__(self, split_feature=None, split_threshold=None):\n",
    "        super().__init__()\n",
    "        self.split_feature = split_feature  # Feature used for splitting\n",
    "        self.split_threshold = split_threshold  # Threshold for the split\n",
    "        self.left_child = None  \n",
    "        self.right_child = None  \n",
    "\n",
    "    def add_left_child(self, left_child):\n",
    "        self.left_child = left_child\n",
    "    \n",
    "    def add_right_child(self, right_child):\n",
    "        self.right_child = right_child\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:109: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  p_y1 = np.sum(labels)/len(labels)\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:165: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:165: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:109: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  p_y1 = np.sum(labels)/len(labels)\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:165: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:165: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:109: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  p_y1 = np.sum(labels)/len(labels)\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:165: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:165: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:109: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  p_y1 = np.sum(labels)/len(labels)\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:165: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n",
      "C:\\Users\\Nicor\\AppData\\Local\\Temp\\ipykernel_13632\\1139137554.py:165: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Notes: GainRatio(D,S) = InfoGain(D,S)/H_D(S)\n",
    "#        InfoGain(D,S) = H_D(S) - H_D(Y|S)\n",
    "#        H_D(S) = -sum(P(y)*log_2(P(y)))        <- emperically determined \n",
    "#        H_D(Y|S) = f-sum(P(S=s)H(Y|S=s)) where \n",
    "#        H(Y|S=s) = -sum(P(Y=y|S=s)*log_2(P(Y=y|S=s)))\n",
    "\n",
    "def MakeSubtree(D):\n",
    "\n",
    "    \"\"\" MakeSubtree(set of training instances D)\n",
    "      C = DetermineCandidateSplits(D)\n",
    "      if stopping criteria is met\n",
    "          make a leaf node N\n",
    "          determine class label for N\n",
    "      else\n",
    "          make an internal node N\n",
    "          S = FindBestSplit(D, C)\n",
    "          for each group k of S\n",
    "                  Dk = subset of training data in group k\n",
    "                  kth child of N = MakeSubtree(Dk)\n",
    "      return subtree rooted at N \"\"\"\n",
    "    \n",
    "    if len(D) == 0: \n",
    "        N = LeafNode() # leaf node N\n",
    "        N.class_label = 1 # classify y=1 if there's no data\n",
    "        return N\n",
    "    \n",
    "    # check if all the labels are the same. Create leaf node if so\n",
    "    # Check if all elements in the last column are the same value\n",
    "    if np.all(D[:, -1] == D[0][-1]):\n",
    "        N = LeafNode()\n",
    "        N.class_label = int(D[0][-1])\n",
    "        return N \n",
    "    \n",
    "    C_x0 = DetermineCandidateSplits(D,0)\n",
    "    C_x1 = DetermineCandidateSplits(D,1)\n",
    "    C = np.concatenate((C_x0, C_x1), axis=0)\n",
    "\n",
    "    if stoppingCriteria(D,C):\n",
    "        # make leaf node \n",
    "        N = LeafNode()\n",
    "        # determine class label\n",
    "        labels = D[:, 2]\n",
    "        # Calculate the mode of the label column\n",
    "        mode_label = np.argmax(np.bincount(labels))\n",
    "        # set the leaf value to the most frequent label\n",
    "        N.class_label = int(mode_label)\n",
    "    else:\n",
    "        # make an internal node \n",
    "        N = InternalNode()\n",
    "        S = FindBestSplit(D,C) # returns a single split of the form [x1, x2, label, keyFeatureIndex]\n",
    "\n",
    "        # get split feature and threshold value\n",
    "        N.split_feature = int(S[-1])\n",
    "        featureAxis = int(S[-1])\n",
    "        N.split_threshold = S[featureAxis]  \n",
    "\n",
    "        # split the data into left and right childs\n",
    "        # first, find the indices that sort D along the featureAxis\n",
    "        sorted_indices = np.argsort(D[:, featureAxis])\n",
    "\n",
    "        # then, sort D according to these indices \n",
    "        Dsorted = D[sorted_indices]\n",
    "\n",
    "        # find the index in Dsorted corresponding to the best split S\n",
    "        splitIndex = np.where(np.all(Dsorted == S[0:3], axis=1))\n",
    "        splitIndex = int(splitIndex[0][0])\n",
    "        # if there are key feature values in Dsorted with the same featue value but are behind the splitIndex, move the splitIndex down. \n",
    "        for j in range(splitIndex):\n",
    "            # check if we're at the first index\n",
    "            if splitIndex == 0:\n",
    "                break\n",
    "            if Dsorted[splitIndex-1][featureAxis] == S[featureAxis]:\n",
    "                splitIndex = splitIndex - 1\n",
    "\n",
    "        Dright = Dsorted[:splitIndex]\n",
    "        Dleft = Dsorted[splitIndex:]\n",
    "        Dsplit = [Dleft, Dright]\n",
    "\n",
    "        for i in range(2): # let i=0 be the left group, i=1 be the right\n",
    "            Dk = Dsplit[i] \n",
    "            if i == 0:\n",
    "                N.add_left_child(MakeSubtree(Dk))\n",
    "            else:\n",
    "                N.add_right_child(MakeSubtree(Dk))\n",
    "\n",
    "    return N \n",
    "\n",
    "\n",
    "def FindBestSplit(D,C):\n",
    "    gain_ratios = []\n",
    "    for i in range(len(C)):\n",
    "        gain_ratios.append(GainRatio_and_SplitEntropy(D,C[i])[0])\n",
    "    max_index = gain_ratios.index(max(gain_ratios))\n",
    "    return C[max_index]\n",
    "\n",
    "# works correctly with example \n",
    "def GainRatio_and_SplitEntropy(D,s):\n",
    "    \"\"\" \n",
    "    Parameters:\n",
    "        D: 2D np.array - data features and labels \n",
    "        \n",
    "        s: np.array - a single split with the feature values, label, and feature index intended to split on.\n",
    "            e.g.: np.array[float, float, int, int] e.g.: [0.234, 1.356, 0, 0]\n",
    "    Output:\n",
    "        G: list - the information gain ratio associated to a given split and the entropy of that split.\n",
    "       \"\"\"\n",
    "    def HY(D):\n",
    "        labels = D[:,2] # array[0,1,1,0,...]\n",
    "        p_y1 = np.sum(labels)/len(labels) \n",
    "        p_y2 = 1 - p_y1\n",
    "        if p_y1 == 0 or p_y2 == 0:\n",
    "            return 0 # Entropy is zero is one of the probabilities is zero\n",
    "        return -(p_y1*np.log2(p_y1) + p_y2*np.log2(p_y2))\n",
    "\n",
    "    # calculate H_D(Y) = -sum[P(y)log(P(y))]                    TERM 1\n",
    "    entropyY = HY(D)\n",
    "\n",
    "    # calculate H_D(Y|S)                                        TERM 2\n",
    "    #sort D by xi values into Dleft (>= s) and Dright (< s)\n",
    "    # sorted_indices = np.argsort(D[:, int(s[3])])\n",
    "    # Dsorted = D[sorted_indices]\n",
    "\n",
    "    # # Find the indices where D equals the specified feature values\n",
    "    # splitIndex = np.where(np.all(Dsorted == s[0:3], axis=1))\n",
    "\n",
    "    # Dright = Dsorted[:splitIndex[0][0]]\n",
    "    # Dleft = Dsorted[splitIndex[0][0]:]\n",
    "\n",
    "    # split the data into left and right childs\n",
    "    # first, find the indices that sort D along the featureAxis\n",
    "    featureAxis = int(s[3])\n",
    "    sorted_indices = np.argsort(D[:, featureAxis])\n",
    "\n",
    "    # then, sort D according to these indices \n",
    "    Dsorted = D[sorted_indices]\n",
    "\n",
    "    # find the index in Dsorted corresponding to the best split S\n",
    "    splitIndex = np.where(np.all(Dsorted == s[0:3], axis=1))\n",
    "    splitIndex = int(splitIndex[0][0])\n",
    "    # if there are key feature values in Dsorted with the same featue value but are behind the splitIndex, move the splitIndex down. \n",
    "    for j in range(splitIndex):\n",
    "        # check if we're at the first index\n",
    "        if splitIndex == 0:\n",
    "            break\n",
    "        if Dsorted[splitIndex-1][featureAxis] == s[featureAxis]:\n",
    "            splitIndex = splitIndex - 1\n",
    "\n",
    "    Dright = Dsorted[:splitIndex]\n",
    "    Dleft = Dsorted[splitIndex:]\n",
    "\n",
    "\n",
    "    # calculate H(Y|Sleft) and H(Y|Sright)\n",
    "    entropyY_given_Sleft = HY(Dleft)\n",
    "    entropyY_given_Sright = HY(Dright)\n",
    "\n",
    "    # finally calculate H_D(Y|S)\n",
    "    Pleft = len(Dleft)/len(D)\n",
    "    Pright = 1 - Pleft\n",
    "    entropyY_givenS = Pleft*entropyY_given_Sleft + Pright*entropyY_given_Sright\n",
    "\n",
    "    # calcualte H_D(S)                                          DENOMINATOR\n",
    "    l = len(Dleft)\n",
    "    r = len(Dright)\n",
    "    t = len(D)\n",
    "    entropyS = -(l/t*np.log2(l/t) + r/t*np.log2(r/t))\n",
    "\n",
    "    # put it all together                                       FULL EXPRESSION\n",
    "    GainRatio = (entropyY - entropyY_givenS)/entropyS   \n",
    "\n",
    "    # check for zero entropies:\n",
    "    if np.isnan(GainRatio):\n",
    "        GainRatio = 0.0\n",
    "    if np.isnan(entropyS):\n",
    "        entropyS = 0.0\n",
    "          \n",
    "    return [GainRatio, entropyS]           \n",
    "\n",
    "\n",
    "def stoppingCriteria(D,C):\n",
    "    \"\"\" \n",
    "     Parameters: D  - np.array with data containing features and labels\n",
    "                 C  - np.array with rows from D indicating candidate splits and an \n",
    "                      extra column indicating the index of the key splitting feature.\n",
    "\n",
    "     Returns:    bool: weather or not to stop splitting\n",
    "       \"\"\"\n",
    "    if len(D) == 0:\n",
    "        return True\n",
    "    # see if H_D(S) = 0 for ALL candidate split\n",
    "    G = []\n",
    "    H_S = []\n",
    "    for i in range(len(C)):\n",
    "        # calculate GainRatio G and split entropy H_S\n",
    "        G.append(GainRatio_and_SplitEntropy(D,C[i])[0])\n",
    "        H_S.append(GainRatio_and_SplitEntropy(D,C[i])[1])\n",
    "    \n",
    "    # if the GainRatio or SplitEntropy are zero for all candidate splits, stop.\n",
    "    if all(item == 0 for item in H_S) or all(item == 0 for item in G):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def DetermineCandidateSplits(D, Xi):\n",
    "    \"\"\" // Run this subroutine for each numeric feature at each node of DT induction\n",
    "DetermineCandidateNumericSplits(set of training instances D, feature Xi)\n",
    "      C = {} // initialize set of candidate splits for feature Xi\n",
    "      let vj denote the value of Xi\n",
    "      for the jth data point\n",
    "      sort the dataset using vj\n",
    "      as the key for each data point\n",
    "      for each pair of adjacent vj, vj+1 in the sorted order\n",
    "          if the corresponding class labels are different\n",
    "              add candidate split vj to C\n",
    "return C \"\"\"\n",
    "\n",
    "    \"\"\" Parameters: D  - np.array with two dimensions with features and labels\n",
    "                    Xi - int index of feature to use for splitting\n",
    "        Returns:    C  - np.array with two dimensions with candidate splits. The last column\n",
    "                      in C is key feature that the split is based on.\n",
    "       \"\"\"\n",
    "    \n",
    "    C = [] # candidate splits for feature Xi\n",
    "    sorted_indices = np.argsort(D[:, Xi])\n",
    "    featureColumn = []\n",
    "    v = D[sorted_indices]\n",
    "    for i in range(len(v)-1):\n",
    "        # check for when labels change \n",
    "        if v[i,2] != v[i+1,2]:\n",
    "            # check for duplicate splits \n",
    "            # extract column Xi from C\n",
    "            if len(C) != 0:\n",
    "                featureColumn = [row[Xi] for row in C]\n",
    "            # check if v[Xi] is in column. If yes, duplicate is True. Else, duplicate is False.\n",
    "            duplicate = v[i+1][Xi] in featureColumn\n",
    "            if (not duplicate):\n",
    "                C.append(v[i+1])\n",
    "    C = np.array(C)\n",
    "\n",
    "    # add column indicating key feature index\n",
    "    new_column = np.full((C.shape[0], 1), Xi, dtype=int)\n",
    "\n",
    "    # Append the 'new_column' to C\n",
    "    C = np.concatenate((C, new_column), axis=1)\n",
    "    return C\n",
    "\n",
    "# C = DetermineCandidateSplits(D,0)\n",
    "# C\n",
    "# D = np.array([[0,0,1],[0.1,0.2,0],[0.3,0.4,1]])\n",
    "# s = [0.3,0.4,1,0]\n",
    "# print(D)\n",
    "# print(s)\n",
    "# print(GainRatio_and_SplitEntropy(D,s))\n",
    "#D = np.vstack((D, [0.2,0.1,0]))\n",
    "myTree = MakeSubtree(D)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Node\n",
      "(Split: 1, Threshold: 8.0)\n",
      "│   └───├───Left: Leaf Node (Class: 1)\n",
      "│   └───├───Right: Internal Node\n",
      "(Split: 1, Threshold: 0.0)\n",
      "│   │   └───├───Left: Internal Node\n",
      "(Split: 1, Threshold: 6.0)\n",
      "│   │   │   └───├───Left: Internal Node\n",
      "(Split: 1, Threshold: 7.0)\n",
      "│   │   │   │   └───├───Left: Leaf Node (Class: 0)\n",
      "│   │   │   │   └───├───Right: Leaf Node (Class: 1)\n",
      "│   │   │   └───├───Right: Leaf Node (Class: 0)\n",
      "│   │   └───├───Right: Internal Node\n",
      "(Split: 0, Threshold: 0.1)\n",
      "│   │   │   └───├───Left: Leaf Node (Class: 0)\n",
      "│   │   │   └───├───Right: Leaf Node (Class: 1)\n"
     ]
    }
   ],
   "source": [
    "# visualizing tree\n",
    "def visualize_tree(node, depth=0, parent_prefix=\"\", prefix=\"\"):\n",
    "    if node is not None:\n",
    "        if isinstance(node, LeafNode):\n",
    "            label = \"Leaf Node (Class: {})\".format(node.class_label)\n",
    "        elif isinstance(node, InternalNode):\n",
    "            label = \"Internal Node\\n(Split: {}, Threshold: {})\".format(node.split_feature, node.split_threshold)\n",
    "        else:\n",
    "            label = \"Node\"\n",
    "\n",
    "        line_prefix = \"│   \" * depth + parent_prefix\n",
    "        if depth > 0:\n",
    "            line_prefix += \"├───\"\n",
    "\n",
    "        print(line_prefix + prefix + label)\n",
    "\n",
    "        if isinstance(node, InternalNode):\n",
    "            visualize_tree(node.left_child, depth + 1, \"└───\", \"Left: \")\n",
    "            visualize_tree(node.right_child, depth + 1, \"└───\", \"Right: \")\n",
    "\n",
    "visualize_tree(myTree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
