{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "racial-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-pontiac",
   "metadata": {},
   "source": [
    "# Define learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "absolute-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning parameters\n",
    "batch_size = 512\n",
    "epochs = 100\n",
    "sample_size = 64 # fixed sample size for generator\n",
    "nz = 128 # latent vector size\n",
    "k = 1 # number of steps to apply to the discriminator\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-tenant",
   "metadata": {},
   "source": [
    "# Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "opposite-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file input already exists.\n",
      "Error occurred while processing: input.\n",
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file outputs already exists.\n",
      "Error occurred while processing: outputs.\n",
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file outputs_grad_descent already exists.\n",
      "Error occurred while processing: outputs_grad_descent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file outputs_improved already exists.\n",
      "Error occurred while processing: outputs_improved.\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,)),\n",
    "])\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "# Make input, output folders\n",
    "!mkdir -p input\n",
    "!mkdir -p outputs\n",
    "!mkdir -p outputs_grad_descent\n",
    "!mkdir -p outputs_improved\n",
    "\n",
    "# Load train data\n",
    "train_data = datasets.MNIST(\n",
    "    root='input/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-guitar",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "speaking-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        self.nz = nz\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.nz, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-democracy",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "silent-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_input = 784\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.n_input, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daily-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### GENERATOR #####\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "######################\n",
      "\n",
      "##### DISCRIMINATOR #####\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n",
      "######################\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(nz).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "print('##### GENERATOR #####')\n",
    "print(generator)\n",
    "print('######################')\n",
    "print('\\n##### DISCRIMINATOR #####')\n",
    "print(discriminator)\n",
    "print('######################')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-brooks",
   "metadata": {},
   "source": [
    "# Tools for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "moved-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers\n",
    "optim_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optim_d = optim.Adam(discriminator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "irish-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "suited-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_g = [] # to store generator loss after each epoch\n",
    "losses_d = [] # to store discriminator loss after each epoch\n",
    "images = [] # to store images generatd by the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sensitive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create real labels (1s)\n",
    "def label_real(size):\n",
    "    data = torch.ones(size, 1)\n",
    "    return data.to(device)\n",
    "# to create fake labels (0s)\n",
    "def label_fake(size):\n",
    "    data = torch.zeros(size, 1)\n",
    "    return data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "australian-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the noise vector\n",
    "def create_noise(sample_size, nz):\n",
    "    return torch.randn(sample_size, nz).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "extraordinary-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the images generated by the generator\n",
    "def save_generator_image(image, path):\n",
    "    save_image(image, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "greatest-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the noise vector - fixed to track how GAN is trained.\n",
    "noise = create_noise(sample_size, nz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-theme",
   "metadata": {},
   "source": [
    "# Q. Write training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ascend D gradient $$\\nabla_{\\theta_{d}} \\big ( \\cfrac{1}{m}  \\sum_{i=1}^{m}  \\log D(x^{(i)})  + \\cfrac{1}{n_{z}} \\sum_{i=1}^{n_{z}}  \\log (1-D(G(z^{(i)})))\\big )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "beginning-champagne",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 4/117 [00:35<16:47,  8.91s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nicor\\OneDrive\\Documents\\Sem 9\\ECE 760\\HW6\\gan-base.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m loss_g \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss_d \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m bi, data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(train_loader), total\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(train_data)\u001b[39m/\u001b[39mtrain_loader\u001b[39m.\u001b[39mbatch_size)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m############ YOUR CODE HERE ########## \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# One batch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# bi is number of times looped \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m# data[0] is 512 (batch size) inputs x1,...,x512 \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# data[1] is 512 with label 0-9\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# sample mini batch of nz noise samples\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# Sample mini batch of {x1,...,xm} -> \"data\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# Train Discriminator\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m# Real Images\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     real_images \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nicor/OneDrive/Documents/Sem%209/ECE%20760/HW6/gan-base.ipynb#X26sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     labels_real \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(real_images), \u001b[39m1\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:270\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    263\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\Nicor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:360\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstd evaluated to zero after conversion to \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m, leading to division by zero.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    359\u001b[0m \u001b[39mif\u001b[39;00m mean\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 360\u001b[0m     mean \u001b[39m=\u001b[39m mean\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    361\u001b[0m \u001b[39mif\u001b[39;00m std\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    362\u001b[0m     std \u001b[39m=\u001b[39m std\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7777)\n",
    "\n",
    "def generator_loss(output, descent=False):\n",
    "    ############ YOUR CODE HERE ##########\n",
    "    # Generator tries to make the discriminator output 1 for fake images if using gradient ascent \n",
    "    # Generator tries to make the drisciminator output 0 for gradient descent \n",
    "    if descent:\n",
    "        # When using gradient descent, minimize log(1 - D(G(z)))\n",
    "        # This approach penalizes the generator more as it improves\n",
    "        #labels = torch.zeros_like(output, device=output.device)\n",
    "        #loss = criterion(output, labels)\n",
    "        loss = torch.mean(torch.log(1 - output))  # clamp to avoid log(0)\n",
    "        return loss  # Negative sign because we're doing descent\n",
    "    else:\n",
    "        # Traditional approach: maximize log(D(G(z)))\n",
    "        # The generator tries to make the discriminator output 1 for fake images\n",
    "        labels = torch.ones_like(output, device=output.device)\n",
    "        return criterion(output, labels)\n",
    "\n",
    "def discriminator_loss(output, true_label):\n",
    "    ############ YOUR CODE HERE ##########\n",
    "    # Discriminator tries to correctly classify real and fake images\n",
    "    criterion = nn.BCELoss()\n",
    "    return criterion(output, true_label)\n",
    "    ######################################\n",
    "    \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_g = 0.0\n",
    "    loss_d = 0.0\n",
    "    for bi, data in tqdm(enumerate(train_loader), total=int(len(train_data)/train_loader.batch_size)):\n",
    "        ############ YOUR CODE HERE ########## \n",
    "        # One batch\n",
    "        # bi is number of times looped \n",
    "        # data[0] is 512 (batch size) inputs x1,...,x512 \n",
    "        # data[1] is 512 with label 0-9\n",
    "\n",
    "        # sample mini batch of nz noise samples\n",
    "        # Sample mini batch of {x1,...,xm} -> \"data\"\n",
    "        \n",
    "        # Train Discriminator\n",
    "        # Real Images\n",
    "        real_images = data[0].to(device)\n",
    "        labels_real = torch.ones(len(real_images), 1, device=device)\n",
    "        outputs_real = discriminator.forward(real_images)\n",
    "        loss_d_real = discriminator_loss(outputs_real, labels_real)\n",
    "        \n",
    "        # Fake Images\n",
    "        # noise_batch = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        noise_batch = torch.randn(batch_size, nz).to(device)\n",
    "        fake_images = generator.forward(noise_batch)\n",
    "        labels_fake = torch.zeros(batch_size, 1, device=device)\n",
    "        outputs_fake = discriminator.forward(fake_images.detach())\n",
    "        loss_d_fake = discriminator_loss(outputs_fake, labels_fake)\n",
    "\n",
    "        # Combine losses and update discriminator\n",
    "        loss_d_total = loss_d_real + loss_d_fake\n",
    "        optim_d.zero_grad()\n",
    "        loss_d_total.backward()\n",
    "        optim_d.step()\n",
    "\n",
    "        # Train Generator\n",
    "        outputs_fake = discriminator.forward(fake_images) # comment out? \n",
    "        # loss_g = generator_loss(outputs_fake) # gradient ascent \n",
    "        loss_g = generator_loss(outputs_fake, descent=True) # gradient descent\n",
    "        optim_g.zero_grad()\n",
    "        loss_g.backward()\n",
    "        optim_g.step()\n",
    "\n",
    "        # Update running loss totals\n",
    "        loss_g += loss_g.item()\n",
    "        loss_d += loss_d_total.item()\n",
    "\n",
    "        ######################################\n",
    "     \n",
    "    \n",
    "    # create the final fake image for the epoch\n",
    "    generated_img = generator(noise).cpu().detach()\n",
    "    \n",
    "    # make the images as grid\n",
    "    generated_img = make_grid(generated_img)\n",
    "    \n",
    "    # visualize generated images\n",
    "    if (epoch == 0):\n",
    "        plt.imshow(generated_img.permute(1, 2, 0))\n",
    "        plt.title(f'epoch {epoch+1}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        plt.imshow(generated_img.permute(1, 2, 0))\n",
    "        plt.title(f'epoch {epoch+1}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # save the generated torch tensor models to disk\n",
    "    save_generator_image(generated_img, f\"outputs_grad_descent/gen_img{epoch+1}.png\")\n",
    "    images.append(generated_img)\n",
    "    epoch_loss_g = loss_g / bi # total generator loss for the epoch\n",
    "    epoch_loss_d = loss_d / bi # total discriminator loss for the epoch\n",
    "    losses_g.append(epoch_loss_g)\n",
    "    losses_d.append(epoch_loss_d)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chief-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE TRAINING\n"
     ]
    }
   ],
   "source": [
    "print('DONE TRAINING')\n",
    "torch.save(generator.state_dict(), 'outputs_grad_descent/generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "relative-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the generated images as GIF file\n",
    "imgs = [np.array(to_pil_image(img)) for img in images]\n",
    "imageio.mimsave('outputs_grad_descent/generator_images.gif', imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "liable-toronto",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and save the generator and discriminator loss\n",
    "def convert_to_floats(lst):\n",
    "    float_list = []\n",
    "    for item in lst:\n",
    "        # Check if the item is a tensor\n",
    "        if torch.is_tensor(item):\n",
    "            # Convert tensor to a Python float\n",
    "            float_list.append(item.item())\n",
    "        else:\n",
    "            # Convert to float if it's not a tensor\n",
    "            float_list.append(float(item))\n",
    "    return float_list\n",
    "\n",
    "losses_d = convert_to_floats(losses_d)\n",
    "losses_g = convert_to_floats(losses_g)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses_g, label='Generator loss')\n",
    "plt.plot(losses_d, label='Discriminator Loss')\n",
    "plt.legend()\n",
    "plt.savefig('outputs_grad_descent/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
